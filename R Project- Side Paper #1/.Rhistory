Sys.sleep(pause_time)  # Pause before retrying
} else {
stop(e)  # For other errors, stop the execution
}
})
}
if (!success) {
cat("Failed to fetch data for keyword:", keyword, "and year:", year, "after", retry_limit, "retries.\n")
}
}
}
years <- 2010:2022
retry_limit <- 5  # Number of times to retry on error
pause_time <- 60  # Time in seconds to pause before retrying
for (i in 1:nrow(kwlist)) {
keyword <- kwlist[i, 1]
for (year in years) {
success <- FALSE
retry_count <- 0
while (!success && retry_count < retry_limit) {
tryCatch({
# Fetch trends data
trends <- gtrends(keyword = c(keyword, "IT Job"),
geo = c('US-CA'),
time = paste0(year, "-01-01 ", year, "-12-31"),
gprop = "web",
low_search_volume = TRUE,
cookie_url = "http://trends.google.com/Cookies/NID")
# DMA: Clean
trendsbyDMA <- data.frame(trends$interest_by_dma)
trendsbyDMA <- trendsbyDMA %>% dplyr::select(-geo, -gprop)
# DMA: Split query of interest and standardizing query into different columns
trendsbyDMA.IT <- trendsbyDMA %>% subset(keyword == "IT Job")
trendsbyDMA <- trendsbyDMA %>% subset(keyword != "IT Job")
trendsbyDMA <- full_join(trendsbyDMA, trendsbyDMA.IT, by = "location")
# DMA: Divide query of interest by standardizing query
trendsbyDMA$KeywordStandardized <- trendsbyDMA[, 2] / trendsbyDMA[, 4]
colnames(trendsbyDMA)[6] <- paste0(keyword, ", ", year)
# DMA: Drop extra columns
trendsbyDMA <- trendsbyDMA %>% dplyr::select(-keyword.x, -keyword.y, -hits.y, -hits.x)
# Combine results
if (is.null(results.DMA)) {
results.DMA <- trendsbyDMA
} else {
results.DMA <- full_join(results.DMA, trendsbyDMA, by = "location")
}
success <- TRUE  # Set success to TRUE if no error occurs
}, error = function(e) {
if (grepl("Status code was not 200. Returned status code: 429", e$message)) {
retry_count <- retry_count + 1
cat("Encountered 429 error. Retry", retry_count, "of", retry_limit, "\n")
Sys.sleep(pause_time)  # Pause before retrying
} else {
stop(e)  # For other errors, stop the execution
}
})
}
if (!success) {
cat("Failed to fetch data for keyword:", keyword, "and year:", year, "after", retry_limit, "retries.\n")
}
}
}
years <- 2010:2022
retry_limit <- 5  # Number of times to retry on error
initial_pause_time <- 10  # Initial time in seconds to pause before retrying
max_pause_time <- 300  # Maximum time in seconds to pause before retrying
for (i in 1:nrow(kwlist)) {
keyword <- kwlist[i, 1]
for (year in years) {
success <- FALSE
retry_count <- 0
pause_time <- initial_pause_time
while (!success && retry_count < retry_limit) {
tryCatch({
# Fetch trends data
response <- GET("https://trends.google.com/trends/api/explore",
query = list(keyword = c(keyword, "IT Job"),
geo = c('US-CA'),
time = paste0(year, "-01-01 ", year, "-12-31"),
gprop = "web",
low_search_volume = TRUE),
timeout(30))
if (status_code(response) == 429) {
stop("Status code was not 200. Returned status code: 429")
}
trends <- gtrends(keyword = c(keyword, "IT Job"),
geo = c('US-CA'),
time = paste0(year, "-01-01 ", year, "-12-31"),
gprop = "web",
low_search_volume = TRUE,
cookie_url = "http://trends.google.com/Cookies/NID")
# DMA: Clean
trendsbyDMA <- data.frame(trends$interest_by_dma)
trendsbyDMA <- trendsbyDMA %>% dplyr::select(-geo, -gprop)
# DMA: Split query of interest and standardizing query into different columns
trendsbyDMA.IT <- trendsbyDMA %>% subset(keyword == "IT Job")
trendsbyDMA <- trendsbyDMA %>% subset(keyword != "IT Job")
trendsbyDMA <- full_join(trendsbyDMA, trendsbyDMA.IT, by = "location")
# DMA: Divide query of interest by standardizing query
trendsbyDMA$KeywordStandardized <- trendsbyDMA[, 2] / trendsbyDMA[, 4]
colnames(trendsbyDMA)[6] <- paste0(keyword, ", ", year)
# DMA: Drop extra columns
trendsbyDMA <- trendsbyDMA %>% dplyr::select(-keyword.x, -keyword.y, -hits.y, -hits.x)
# Combine results
if (is.null(results.DMA)) {
results.DMA <- trendsbyDMA
} else {
results.DMA <- full_join(results.DMA, trendsbyDMA, by = "location")
}
success <- TRUE  # Set success to TRUE if no error occurs
}, error = function(e) {
if (grepl("Status code was not 200. Returned status code: 429", e$message)) {
retry_count <- retry_count + 1
cat("Encountered 429 error. Retry", retry_count, "of", retry_limit, "\n")
Sys.sleep(pause_time)  # Pause before retrying
pause_time <- min(pause_time * 2, max_pause_time)  # Exponential backoff
} else {
stop(e)  # For other errors, stop the execution
}
})
}
if (!success) {
cat("Failed to fetch data for keyword:", keyword, "and year:", year, "after", retry_limit, "retries.\n")
}
}
}
library(httr)
years <- 2010:2022
retry_limit <- 5  # Number of times to retry on error
initial_pause_time <- 10  # Initial time in seconds to pause before retrying
max_pause_time <- 300  # Maximum time in seconds to pause before retrying
for (i in 1:nrow(kwlist)) {
keyword <- kwlist[i, 1]
for (year in years) {
success <- FALSE
retry_count <- 0
pause_time <- initial_pause_time
while (!success && retry_count < retry_limit) {
tryCatch({
# Fetch trends data
response <- GET("https://trends.google.com/trends/api/explore",
query = list(keyword = c(keyword, "IT Job"),
geo = c('US-CA'),
time = paste0(year, "-01-01 ", year, "-12-31"),
gprop = "web",
low_search_volume = TRUE),
timeout(30))
if (status_code(response) == 429) {
stop("Status code was not 200. Returned status code: 429")
}
trends <- gtrends(keyword = c(keyword, "IT Job"),
geo = c('US-CA'),
time = paste0(year, "-01-01 ", year, "-12-31"),
gprop = "web",
low_search_volume = TRUE,
cookie_url = "http://trends.google.com/Cookies/NID")
# DMA: Clean
trendsbyDMA <- data.frame(trends$interest_by_dma)
trendsbyDMA <- trendsbyDMA %>% dplyr::select(-geo, -gprop)
# DMA: Split query of interest and standardizing query into different columns
trendsbyDMA.IT <- trendsbyDMA %>% subset(keyword == "IT Job")
trendsbyDMA <- trendsbyDMA %>% subset(keyword != "IT Job")
trendsbyDMA <- full_join(trendsbyDMA, trendsbyDMA.IT, by = "location")
# DMA: Divide query of interest by standardizing query
trendsbyDMA$KeywordStandardized <- trendsbyDMA[, 2] / trendsbyDMA[, 4]
colnames(trendsbyDMA)[6] <- paste0(keyword, ", ", year)
# DMA: Drop extra columns
trendsbyDMA <- trendsbyDMA %>% dplyr::select(-keyword.x, -keyword.y, -hits.y, -hits.x)
# Combine results
if (is.null(results.DMA)) {
results.DMA <- trendsbyDMA
} else {
results.DMA <- full_join(results.DMA, trendsbyDMA, by = "location")
}
success <- TRUE  # Set success to TRUE if no error occurs
}, error = function(e) {
if (grepl("Status code was not 200. Returned status code: 429", e$message)) {
retry_count <- retry_count + 1
cat("Encountered 429 error. Retry", retry_count, "of", retry_limit, "\n")
Sys.sleep(pause_time)  # Pause before retrying
pause_time <- min(pause_time * 2, max_pause_time)  # Exponential backoff
} else {
stop(e)  # For other errors, stop the execution
}
})
}
if (!success) {
cat("Failed to fetch data for keyword:", keyword, "and year:", year, "after", retry_limit, "retries.\n")
}
}
}
results.DMA <- NULL  # Initialize results.DMA
for (i in 1:nrow(kwlist)) {
keyword <- kwlist[i, 1]
for (year in years) {
success <- FALSE
retry_count <- 0
pause_time <- initial_pause_time
while (!success && retry_count < retry_limit) {
tryCatch({
# Fetch trends data
response <- GET("https://trends.google.com/trends/api/explore",
query = list(keyword = c(keyword, "IT Job"),
geo = c('US-CA'),
time = paste0(year, "-01-01 ", year, "-12-31"),
gprop = "web",
low_search_volume = TRUE),
timeout(30))
if (status_code(response) == 429) {
stop("Status code was not 200. Returned status code: 429")
}
trends <- gtrends(keyword = c(keyword, "IT Job"),
geo = c('US-CA'),
time = paste0(year, "-01-01 ", year, "-12-31"),
gprop = "web",
low_search_volume = TRUE,
cookie_url = "http://trends.google.com/Cookies/NID")
# DMA: Clean
trendsbyDMA <- data.frame(trends$interest_by_dma)
trendsbyDMA <- trendsbyDMA %>% dplyr::select(-geo, -gprop)
# DMA: Split query of interest and standardizing query into different columns
trendsbyDMA.IT <- trendsbyDMA %>% subset(keyword == "IT Job")
trendsbyDMA <- trendsbyDMA %>% subset(keyword != "IT Job")
trendsbyDMA <- full_join(trendsbyDMA, trendsbyDMA.IT, by = "location")
# DMA: Divide query of interest by standardizing query
trendsbyDMA$KeywordStandardized <- trendsbyDMA[, 2] / trendsbyDMA[, 4]
colnames(trendsbyDMA)[6] <- paste0(keyword, ", ", year)
# DMA: Drop extra columns
trendsbyDMA <- trendsbyDMA %>% dplyr::select(-keyword.x, -keyword.y, -hits.y, -hits.x)
# Combine results
if (is.null(results.DMA)) {
results.DMA <- trendsbyDMA
} else {
results.DMA <- full_join(results.DMA, trendsbyDMA, by = "location")
}
success <- TRUE  # Set success to TRUE if no error occurs
}, error = function(e) {
if (grepl("Status code was not 200. Returned status code: 429", e$message)) {
retry_count <- retry_count + 1
cat("Encountered 429 error. Retry", retry_count, "of", retry_limit, "\n")
Sys.sleep(pause_time)  # Pause before retrying
pause_time <- min(pause_time * 2, max_pause_time)  # Exponential backoff
} else {
stop(e)  # For other errors, stop the execution
}
})
}
if (!success) {
cat("Failed to fetch data for keyword:", keyword, "and year:", year, "after", retry_limit, "retries.\n")
}
}
}
years <- 2010:2022
retry_limit <- 5  # Number of times to retry on error
pause_time <- 60  # Time in seconds to pause before retrying
results.DMA <- NULL  # Initialize results.DMA
for (i in 1:nrow(kwlist)) {
keyword <- kwlist[i, 1]
for (year in years) {
success <- FALSE
retry_count <- 0
while (!success && retry_count < retry_limit) {
tryCatch({
# Fetch trends data
trends <- gtrends(keyword = c(keyword, "IT Job"),
geo = c('US-CA'),
time = paste0(year, "-01-01 ", year, "-12-31"),
gprop = "web",
low_search_volume = TRUE,
cookie_url = "http://trends.google.com/Cookies/NID")
# DMA: Clean
trendsbyDMA <- data.frame(trends$interest_by_dma)
trendsbyDMA <- trendsbyDMA %>% dplyr::select(-geo, -gprop)
# DMA: Split query of interest and standardizing query into different columns
trendsbyDMA.IT <- trendsbyDMA %>% subset(keyword == "IT Job")
trendsbyDMA <- trendsbyDMA %>% subset(keyword != "IT Job")
trendsbyDMA <- full_join(trendsbyDMA, trendsbyDMA.IT, by = "location")
# DMA: Divide query of interest by standardizing query
trendsbyDMA$KeywordStandardized <- trendsbyDMA[, 2] / trendsbyDMA[, 4]
colnames(trendsbyDMA)[6] <- paste0(keyword, ", ", year)
# DMA: Drop extra columns
trendsbyDMA <- trendsbyDMA %>% dplyr::select(-keyword.x, -keyword.y, -hits.y, -hits.x)
# Combine results
if (is.null(results.DMA)) {
results.DMA <- trendsbyDMA
} else {
results.DMA <- full_join(results.DMA, trendsbyDMA, by = "location")
}
success <- TRUE  # Set success to TRUE if no error occurs
}, error = function(e) {
if (grepl("Status code was not 200. Returned status code: 429", e$message)) {
retry_count <- retry_count + 1
cat("Encountered 429 error. Retry", retry_count, "of", retry_limit, "\n")
Sys.sleep(pause_time)  # Pause before retrying
} else {
stop(e)  # For other errors, stop the execution
}
})
}
if (!success) {
cat("Failed to fetch data for keyword:", keyword, "and year:", year, "after", retry_limit, "retries.\n")
}
}
}
?grepl
trends <- gtrends(keyword = c('McDonalds', 'IT Job'),
geo = c('US-CA'),
time = "2010-01-01 2022-12-31",
gprop = "web",
low_search_volume = TRUE,
cookie_url = "http://trends.google.com/Cookies/NID")
#TIME: Clean
results.time <- data.frame(trends$interest_over_time)
results.time <- results.time %>% dplyr::select(-geo, -time, -gprop, -category)
# TIME: Split query of interest and standardizing query into different columns
results.time.IT <- results.time %>%  subset(keyword == "IT Job")
results.time.IT <- data.frame(results.time.IT, row.names = TRUE)
results.time <- results.time %>%  subset(keyword != "IT Job")
results.time <- data.frame(results.time, row.names = TRUE)
results.time <- cbind(results.time, results.time.IT)
# TIME: Divide query of interest by standardizing query
results.time$KeywordStandardized <- results.time[,1]/results.time[,3]
colnames(results.time)[5] <- paste0(results.time[1, 2])
results.time <- results.time %>% dplyr::select(-keyword, -hits)
# DMA: Clean
results.DMA <- data.frame(trends$interest_by_dma)
results.DMA <- results.DMA %>% dplyr::select(-geo, -gprop)
# DMA: Split query of interest and standardizing query into different columns
results.DMA.IT <- results.DMA %>%  subset(keyword == "IT Job")
results.DMA <- results.DMA %>%  subset(keyword != "IT Job")
results.DMA <- full_join(results.DMA, results.DMA.IT, by = "location")
# DMA: Divide query of interest by standardizing query
results.DMA$KeywordStandardized <- results.DMA[,2]/results.DMA[,4]
colnames(results.DMA)[6] <-paste0(results.DMA[1, 3])
results.DMA <- results.DMA %>% dplyr::select(-keyword.x, -keyword.y, -hits.y, -hits.x)
results.DMA.template <- results.DMA
results.time.template <- results.time
results.DMA <-  results.DMA.template
years <- 2010:2022
retry_limit <- 5  # Number of times to retry on error
pause_time <- 60  # Time in seconds to pause before retrying
for (i in 1:nrow(kwlist)) {
keyword <- kwlist[i, 1]
for (year in years) {
success <- FALSE
retry_count <- 0
while (!success && retry_count < retry_limit) {
tryCatch({
# Fetch trends data
trends <- gtrends(keyword = c(keyword, "IT Job"),
geo = c('US-CA'),
time = paste0(year, "-01-01 ", year, "-12-31"),
gprop = "web",
low_search_volume = TRUE,
cookie_url = "http://trends.google.com/Cookies/NID")
# DMA: Clean
trendsbyDMA <- data.frame(trends$interest_by_dma)
trendsbyDMA <- trendsbyDMA %>% dplyr::select(-geo, -gprop)
# DMA: Split query of interest and standardizing query into different columns
trendsbyDMA.IT <- trendsbyDMA %>% subset(keyword == "IT Job")
trendsbyDMA <- trendsbyDMA %>% subset(keyword != "IT Job")
trendsbyDMA <- full_join(trendsbyDMA, trendsbyDMA.IT, by = "location")
# DMA: Divide query of interest by standardizing query
trendsbyDMA$KeywordStandardized <- trendsbyDMA[, 2] / trendsbyDMA[, 4]
colnames(trendsbyDMA)[6] <- paste0(keyword, ", ", year)
# DMA: Drop extra columns
trendsbyDMA <- trendsbyDMA %>% dplyr::select(-keyword.x, -keyword.y, -hits.y, -hits.x)
# Combine results
if (is.null(results.DMA)) {
results.DMA <- trendsbyDMA
} else {
results.DMA <- full_join(results.DMA, trendsbyDMA, by = "location")
}
success <- TRUE  # Set success to TRUE if no error occurs
}, error = function(e) {
if (grepl("Status code was not 200. Returned status code:429", e$message)) {
retry_count <- retry_count + 1
cat("Encountered 429 error. Retry", retry_count, "of", retry_limit, "\n")
Sys.sleep(pause_time)  # Pause before retrying
} else {
stop(e)  # For other errors, stop the execution
}
})
}
if (!success) {
cat("Failed to fetch data for keyword:", keyword, "and year:", year, "after", retry_limit, "retries.\n")
}
}
}
View(trendsbyDMA)
#Load packages
library(readr)
library(gtrendsR)
library(purrr)
library(GTT)
library(dplyr)
setwd("C:/Users/cjkno/Documents/My Documents/Classes - '23 Spring/Research/Paper (Side) #1/DATA/Google Trends")
# Import keywords list
kwlist <- read.csv("Fast Food Keywords.csv")
results.DMA <-  results.DMA.template
View(results.DMA)
years <- 2010:2022
years <- 2010:2022
retry_limit <- 5  # Number of times to retry on error
pause_time <- 120  # Time in seconds to pause before retrying
for (i in 1:nrow(kwlist)) {
keyword <- kwlist[i, 1]
for (year in years) {
success <- FALSE
retry_count <- 0
while (!success && retry_count < retry_limit) {
tryCatch({
# Fetch trends data
trends <- gtrends(keyword = c(keyword, "IT Job"),
geo = c('US-CA'),
time = paste0(year, "-01-01 ", year, "-12-31"),
gprop = "web",
low_search_volume = TRUE,
cookie_url = "http://trends.google.com/Cookies/NID")
# DMA: Clean
trendsbyDMA <- data.frame(trends$interest_by_dma)
trendsbyDMA <- trendsbyDMA %>% dplyr::select(-geo, -gprop)
# DMA: Split query of interest and standardizing query into different columns
trendsbyDMA.IT <- trendsbyDMA %>% subset(keyword == "IT Job")
trendsbyDMA <- trendsbyDMA %>% subset(keyword != "IT Job")
trendsbyDMA <- full_join(trendsbyDMA, trendsbyDMA.IT, by = "location")
# DMA: Divide query of interest by standardizing query
trendsbyDMA$KeywordStandardized <- trendsbyDMA[, 2] / trendsbyDMA[, 4]
colnames(trendsbyDMA)[6] <- paste0(keyword, ", ", year)
# DMA: Drop extra columns
trendsbyDMA <- trendsbyDMA %>% dplyr::select(-keyword.x, -keyword.y, -hits.y, -hits.x)
# Combine results
results.DMA <- full_join(results.DMA, trendsbyDMA, by = "location")
success <- TRUE  # Set success to TRUE if no error occurs
}, error = function(e) {
if (grepl("Status code was not 200. Returned status code:429", e$message)) {
retry_count <- retry_count + 1
cat("Encountered 429 error. Retry", retry_count, "of", retry_limit, "\n")
Sys.sleep(pause_time)  # Pause before retrying
} else {
stop(e)  # For other errors, stop the execution
}
})
}
if (!success) {
cat("Failed to fetch data for keyword:", keyword, "and year:", year, "after", retry_limit, "retries.\n")
}
}
}
results.DMA
write.csv(results.DMA, file = "GTrends Mined Data - DMA.csv", row.names = T)
### GTRENDSR
# Do simple search to create the empty data frame
trends <- gtrends(keyword = c('McDonalds', 'IT Job'),
geo = c('US-CA'),
time = "2010-01-01 2022-12-31",
gprop = "web",
low_search_volume = TRUE,
cookie_url = "http://trends.google.com/Cookies/NID")
#TIME: Clean
results.time <- data.frame(trends$interest_over_time)
results.time <- results.time %>% dplyr::select(-geo, -time, -gprop, -category)
# TIME: Split query of interest and standardizing query into different columns
results.time.IT <- results.time %>%  subset(keyword == "IT Job")
results.time.IT <- data.frame(results.time.IT, row.names = TRUE)
results.time <- results.time %>%  subset(keyword != "IT Job")
results.time <- data.frame(results.time, row.names = TRUE)
results.time <- cbind(results.time, results.time.IT)
# TIME: Divide query of interest by standardizing query
results.time$KeywordStandardized <- results.time[,1]/results.time[,3]
colnames(results.time)[5] <- paste0(results.time[1, 2])
results.time <- results.time %>% dplyr::select(-keyword, -hits)
results.time.template <- results.time
# DMA: Clean
results.DMA <- data.frame(trends$interest_by_dma)
results.DMA <- results.DMA %>% dplyr::select(-geo, -gprop)
# DMA: Split query of interest and standardizing query into different columns
results.DMA.IT <- results.DMA %>%  subset(keyword == "IT Job")
results.DMA <- results.DMA %>%  subset(keyword != "IT Job")
results.DMA <- full_join(results.DMA, results.DMA.IT, by = "location")
# DMA: Divide query of interest by standardizing query
results.DMA$KeywordStandardized <- results.DMA[,2]/results.DMA[,4]
colnames(results.DMA)[6] <-paste0(results.DMA[1, 3])
results.DMA <- results.DMA %>% dplyr::select(-keyword.x, -keyword.y, -hits.y, -hits.x)
results.DMA.template <- results.DMA
### TIME: For Loop
# Import keywords list
kwlist <- read.csv("Fast Food Keywords.csv")
# Loop gtrends functions and save output to results data frame
for (i in 1:nrow(kwlist)){
trends <- gtrends(keyword = c(kwlist[i, 1], "IT Job"),
geo = c('US-CA'),
time = "2010-01-01 2022-12-31",
gprop = "web",
low_search_volume = TRUE,
cookie_url = "http://trends.google.com/Cookies/NID")
# TIME: Clean
trendsbytime <- data.frame(trends$interest_over_time)
trendsbytime <- trendsbytime %>% dplyr::select(-geo, -time, -gprop, -category)
# TIME: Split query of interest and standardizing query into different columns
trendsbytime.IT <- trendsbytime %>%  subset(keyword == "IT Job")
trendsbytime.IT <- data.frame(trendsbytime.IT, row.names = TRUE)
trendsbytime <- trendsbytime %>%  subset(keyword != "IT Job")
trendsbytime <- data.frame(trendsbytime, row.names = TRUE)
trendsbytime <- cbind(trendsbytime, trendsbytime.IT)
# TIME: Divide query of interest by standardizing query
trendsbytime$KeywordStandardized <- trendsbytime[,1]/trendsbytime[,3]
colnames(trendsbytime)[5] <- paste0(kwlist[i, 1])
trendsbytime <- trendsbytime %>% dplyr::select(-keyword, -hits)
results.time <- cbind(results.time, trendsbytime)
}
View(results.time)
